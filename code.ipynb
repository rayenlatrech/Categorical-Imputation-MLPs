{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de347bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334dd87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting intrain() – training Independent + Conjunct MLPs...\n",
      "Data loaded: (19900, 16)\n",
      "\n",
      "Training 16 Independent MLPs...\n",
      "  → Training f1 (1/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a7f51b9e7c4a7183256e3700eebf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f1:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f2 (2/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb715726cfe4ec893ca5d48316b2ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f2:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f3 (3/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37f614517a2427f9e1dab397816bcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f3:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f4 (4/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acbd29c823c496d974867aa03b3ff5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f4:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f5 (5/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfbc87c0e474bc58ad4877445b2b5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f5:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f6 (6/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98424e05e67245a4aac0b9ccc333377f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f6:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f7 (7/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e35809eb30541fa988fbcc0b81f5417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f7:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f8 (8/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35d3e9eb5cc434bad7c6e569b3a639a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f8:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f9 (9/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d120992e58104d38848a6a77ffc2b85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f9:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f10 (10/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ccffe941834e9cbda04d0324779aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f10:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f11 (11/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b981cf06c84b1abb8167212242c697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f11:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f12 (12/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314e29da8e5b46dd9d185721856f569a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f12:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f13 (13/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f088a9041d44095976dd496394f0f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f13:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f14 (14/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57949ed2856648a087e867c46afc0003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f14:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f15 (15/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6a792f6ba24f239ac1348a1956bc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f15:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training f16 (16/16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c91dfb56f84e4e8061040a8f619efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f16:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Conjunct MLP (autoencoder)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807232612c204338b08debb2b5f076a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conjunct:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INTRAIN COMPLETE → 'models_complete.pth' saved\n"
     ]
    }
   ],
   "source": [
    "def intrain(data_path='DATA.csv'):\n",
    "    print(\"Starting intrain() – training Independent + Conjunct MLPs...\")\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data loaded: {df.shape}\")\n",
    "    \n",
    "    # === PREPROCESSING ===\n",
    "    label_encoders = {}\n",
    "    for col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    ohe.fit(df.values.flatten().reshape(-1, 1))\n",
    "    BLOCK_SIZE = len(ohe.categories_[0])  # 16\n",
    "    \n",
    "    # Encode full dataset\n",
    "    encoded = pd.DataFrame({col: label_encoders[col].transform(df[col]) for col in df.columns})\n",
    "    tensor = torch.tensor(encoded.values, dtype=torch.long)\n",
    "    full_onehot = torch.nn.functional.one_hot(tensor, BLOCK_SIZE).view(-1, BLOCK_SIZE*16).float()\n",
    "    \n",
    "    # === TRAIN 16 INDEPENDENT MLPs ===\n",
    "    print(\"\\nTraining 16 Independent MLPs...\")\n",
    "    independent_models = {}\n",
    "    for col_idx in range(16):\n",
    "        col_name = df.columns[col_idx]\n",
    "        print(f\"  → Training {col_name} ({col_idx+1}/16)\")\n",
    "        \n",
    "        X = full_onehot.clone()\n",
    "        X[:, col_idx*BLOCK_SIZE:(col_idx+1)*BLOCK_SIZE] = 0.0\n",
    "        y = tensor[:, col_idx]\n",
    "        \n",
    "        dataset = TensorDataset(X, y)\n",
    "        loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "        \n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(BLOCK_SIZE*16, 128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, BLOCK_SIZE)\n",
    "        ).to(device)\n",
    "        \n",
    "        opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in tqdm(range(40), desc=col_name, leave=False):\n",
    "            for bx, by in loader:\n",
    "                bx, by = bx.to(device), by.to(device)\n",
    "                opt.zero_grad()\n",
    "                loss = crit(model(bx), by)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        \n",
    "        independent_models[col_name] = model.cpu()\n",
    "    \n",
    "    # === TRAIN CONJUNCT MLP ===\n",
    "    print(\"\\nTraining Conjunct MLP (autoencoder)...\")\n",
    "    conjunct_model = nn.Sequential(\n",
    "        nn.Linear(BLOCK_SIZE*16, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "        nn.Linear(256, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "        nn.Linear(256, BLOCK_SIZE*16)\n",
    "    ).to(device)\n",
    "    \n",
    "    opt = optim.Adam(conjunct_model.parameters(), lr=0.001)\n",
    "    crit = nn.MSELoss()\n",
    "    \n",
    "    conjunct_model.train()\n",
    "    for epoch in tqdm(range(80), desc=\"Conjunct\", leave=False):\n",
    "        for i in range(0, len(full_onehot), 256):\n",
    "            batch = full_onehot[i:i+256].to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(conjunct_model(batch), batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    \n",
    "    conjunct_model = conjunct_model.cpu()\n",
    "    \n",
    "    # === SAVE EVERYTHING ===\n",
    "    torch.save({\n",
    "        'independent_models': independent_models,\n",
    "        'conjunct_model': conjunct_model,\n",
    "        'label_encoders': label_encoders,\n",
    "        'onehot_encoder': ohe,\n",
    "        'block_size': BLOCK_SIZE\n",
    "    }, 'models_complete.pth')\n",
    "    \n",
    "    print(\"\\nINTRAIN COMPLETE → 'models_complete.pth' saved\")\n",
    "    return 'models_complete.pth'\n",
    "\n",
    "# RUN ONCE\n",
    "model_file = intrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e511f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Independent vs Conjunct MLP...\n",
      "\n",
      "FINAL COMPARISON – INDEPENDENT WINS:\n",
      "   missing_rate  independent_best  conjunct_7iters\n",
      "0          0.05            0.9765           0.2241\n",
      "1          0.10            0.9640           0.2239\n",
      "2          0.20            0.9238           0.2238\n",
      "final_accuracy_comparison.csv saved\n"
     ]
    }
   ],
   "source": [
    "def test_and_compare(model_path='models_complete.pth'):\n",
    "    print(\"Testing Independent vs Conjunct MLP...\")\n",
    "    \n",
    "    # FIXED: Load with weights_only=False (you trained this file)\n",
    "    data = torch.load(model_path, weights_only=False)\n",
    "    indep_models = data['independent_models']\n",
    "    conj_model = data['conjunct_model']\n",
    "    le = data['label_encoders']\n",
    "    BLOCK_SIZE = data['block_size']\n",
    "    \n",
    "    df = pd.read_csv('DATA.csv')\n",
    "    _, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Encode test\n",
    "    encoded = pd.DataFrame({col: le[col].transform(test_df[col]) for col in test_df.columns})\n",
    "    tensor = torch.tensor(encoded.values, dtype=torch.long)\n",
    "    test_onehot = torch.nn.functional.one_hot(tensor, BLOCK_SIZE).view(-1, BLOCK_SIZE*16).float()\n",
    "    \n",
    "    # === GLOBAL IMPUTER ===\n",
    "    def impute_independent(X_miss, col_names):\n",
    "        X = X_miss.clone()\n",
    "        with torch.no_grad():\n",
    "            for col_idx in reversed(range(16)):\n",
    "                col_name = col_names[col_idx]\n",
    "                start = col_idx * BLOCK_SIZE\n",
    "                end = start + BLOCK_SIZE\n",
    "                missing = X[:, start:end].sum(dim=1) == 0\n",
    "                if missing.any():\n",
    "                    inp = X.to(device)\n",
    "                    logits = indep_models[col_name].to(device)(inp)[missing]\n",
    "                    probs = torch.softmax(logits / 0.5, dim=1)\n",
    "                    pred = torch.argmax(probs, dim=1)\n",
    "                    onehot = torch.nn.functional.one_hot(pred, BLOCK_SIZE).float()\n",
    "                    X[missing, start:end] = onehot.cpu()\n",
    "            for col_idx in range(16):\n",
    "                col_name = col_names[col_idx]\n",
    "                start = col_idx * BLOCK_SIZE\n",
    "                end = start + BLOCK_SIZE\n",
    "                missing = X[:, start:end].sum(dim=1) == 0\n",
    "                if missing.any():\n",
    "                    inp = X.to(device)\n",
    "                    logits = indep_models[col_name].to(device)(inp)[missing]\n",
    "                    pred = torch.argmax(logits, dim=1)\n",
    "                    onehot = torch.nn.functional.one_hot(pred, BLOCK_SIZE).float()\n",
    "                    X[missing, start:end] = onehot.cpu()\n",
    "        return X\n",
    "    \n",
    "    def impute_conjunct(X_miss, iters=7):\n",
    "        X = X_miss.clone()\n",
    "        conj_model.to(device)\n",
    "        conj_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(iters):\n",
    "                X = X.to(device)\n",
    "                X = conj_model(X)\n",
    "                X = torch.clamp(X, 0, 1)\n",
    "                X = X / (X.sum(dim=1, keepdim=True) + 1e-8)\n",
    "                X = X.cpu()\n",
    "        return X\n",
    "    \n",
    "    def create_missing(rate=0.1, seed=42):\n",
    "        torch.manual_seed(seed)\n",
    "        mask = torch.rand(test_onehot.shape) < rate\n",
    "        X_miss = test_onehot.clone()\n",
    "        X_miss[mask] = 0.0\n",
    "        return X_miss, mask\n",
    "    \n",
    "    def accuracy(imputed, mask):\n",
    "        feature_mask = mask.view(-1, 16, BLOCK_SIZE).sum(dim=2) > 0\n",
    "        pred = torch.argmax(imputed.view(-1, 16, BLOCK_SIZE), dim=2)\n",
    "        true = torch.argmax(test_onehot.view(-1, 16, BLOCK_SIZE), dim=2)\n",
    "        return (pred[feature_mask] == true[feature_mask]).float().mean().item()\n",
    "    \n",
    "    # Run\n",
    "    rates = [0.05, 0.1, 0.2]\n",
    "    results = []\n",
    "    col_names = test_df.columns.tolist()\n",
    "    \n",
    "    for rate in rates:\n",
    "        X_miss, mask = create_missing(rate)\n",
    "        X_indep = impute_independent(X_miss, col_names)\n",
    "        X_conj = impute_conjunct(X_miss)\n",
    "        acc_indep = accuracy(X_indep, mask)\n",
    "        acc_conj = accuracy(X_conj, mask)\n",
    "        results.append({\n",
    "            'missing_rate': rate,\n",
    "            'independent_best': round(acc_indep, 4),\n",
    "            'conjunct_7iters': round(acc_conj, 4)\n",
    "        })\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(\"\\nFINAL COMPARISON – INDEPENDENT WINS:\")\n",
    "    print(df_results)\n",
    "    df_results.to_csv('final_accuracy_comparison.csv', index=False)\n",
    "    print(\"final_accuracy_comparison.csv saved\")\n",
    "    \n",
    "    return df_results, impute_independent\n",
    "\n",
    "# RUN IT\n",
    "results_df, global_imputer = test_and_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(input_path='In?ut.csv', output_path='Imputed_Output.csv'):\n",
    "    print(f\"QUERY: Imputing {input_path} → {output_path}\")\n",
    "    \n",
    "    \n",
    "    data = torch.load('models_complete.pth', weights_only=False)\n",
    "    indep_models = data['independent_models']\n",
    "    le = data['label_encoders']\n",
    "    BLOCK_SIZE = data['block_size']\n",
    "    \n",
    "    input_df = pd.read_csv(input_path)\n",
    "    print(f\"Input shape: {input_df.shape}\")\n",
    "    \n",
    "    encoded = pd.DataFrame()\n",
    "    for col in input_df.columns:\n",
    "        col_data = input_df[col].fillna('A')\n",
    "        col_data = col_data.astype(str)\n",
    "        col_data = col_data.apply(lambda x: x if x in le[col].classes_ else le[col].classes_[0])\n",
    "        encoded[col] = le[col].transform(col_data)\n",
    "    \n",
    "    tensor = torch.tensor(encoded.values, dtype=torch.long)\n",
    "    X_miss = torch.nn.functional.one_hot(tensor, BLOCK_SIZE).view(-1, BLOCK_SIZE*16).float()\n",
    "    \n",
    "    for col_idx, col in enumerate(input_df.columns):\n",
    "        missing = input_df[col].isna() | (input_df[col].astype(str) == '') | (input_df[col].astype(str) == '?')\n",
    "        if missing.any():\n",
    "            start = col_idx * BLOCK_SIZE\n",
    "            end = start + BLOCK_SIZE\n",
    "            X_miss[missing, start:end] = 0.0\n",
    "    \n",
    "    X_filled = global_imputer(X_miss, input_df.columns.tolist())\n",
    "    \n",
    "    labels = torch.argmax(X_filled.view(-1, 16, BLOCK_SIZE), dim=2)\n",
    "    result = pd.DataFrame()\n",
    "    for i, col in enumerate(input_df.columns):\n",
    "        result[col] = le[col].inverse_transform(labels[:, i].cpu().numpy())\n",
    "    \n",
    "    result.to_csv(output_path, index=False)\n",
    "    print(f\"IMPUTED FILE SAVED → {output_path}\")\n",
    "    display(result.head())\n",
    "    return result\n",
    "\n",
    "# query('In?ut.csv', 'MY_SUBMISSION.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
